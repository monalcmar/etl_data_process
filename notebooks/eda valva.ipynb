{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "In this notebook the data given by different excel files is explored in order to define the details and constrains in the desing of the Data Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerias python\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar modulos propios en notebook\n",
    "project_root = Path(os.getcwd()).parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Verifica que el directorio fue agregado\n",
    "print(\"Directorio en sys.path:\", project_root in sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from db.connection import engine_setting, engine_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "rootFolder = Path.cwd().parent\n",
    "\n",
    "excel_path_1_bonos_trab =  rootFolder / \"data\" / \"U532-2024-11-05.xls\"\n",
    "excel_path_2_taller_orden_rep =  rootFolder / \"data\" / \"U533-2024-11-05.xls\"\n",
    "excel_path_3_bonos_pres =  rootFolder / \"data\" / \"U551-2024-11-05.xls\"\n",
    "excel_path_4_stock =  rootFolder / \"data\" / \"U552-2024-11-05.xls\"\n",
    "excel_path_5_compras =  rootFolder / \"data\" / \"U553-2024-11-05.xls\"\n",
    "excel_path_6_mostrador =  rootFolder / \"data\" / \"U554-2024-11-05.xls\"\n",
    "excel_path_7_invertidas =  rootFolder / \"data\" / \"U555-2024-11-05.xls\"\n",
    "excel_path_8_taller_orden_venta =  rootFolder / \"data\" / \"U560-2024-11-05.xls\"\n",
    "excel_path_9_cliente =  rootFolder / \"data\" / \"U6301303-conta-2024-11-06.xls\"\n",
    "excel_path_10_articulo =  rootFolder / \"data\" / \"U6301303-taller-2024-11-05.xls\"\n",
    "excel_path_11_empresas =  rootFolder / \"data\" / \"U6311303-conta-2024-11-06.xls\"\n",
    "excel_path_12_talleres =  rootFolder / \"data\" / \"U6311303-taller-2024-11-05.xls\"\n",
    "excel_path_13_almacenes =  rootFolder / \"data\" / \"U6321303-2024-11-05.xls\"\n",
    "excel_path_14_operarios =  rootFolder / \"data\" / \"U6331303-2024-11-05.xls\"\n",
    "excel_path_15_vehiculo =  rootFolder / \"data\" / \"U6341303-2024-11-05.xls\"\n",
    "excel_path_16_tipos_horas =  rootFolder / \"data\" / \"ULSTTHPT-2024-11-05.xls\"\n",
    "excel_path_17_tipos_venta =  rootFolder / \"data\" / \"ULSTTVPT-2024-11-05.xls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo Excel con la ruta completa\n",
    "df_bonos_trab = pd.read_excel(excel_path_1_bonos_trab)\n",
    "df_taller_orden_rep = pd.read_excel(excel_path_2_taller_orden_rep)\n",
    "df_bono_pres = pd.read_excel(excel_path_3_bonos_pres)\n",
    "df_stock = pd.read_excel(excel_path_4_stock)\n",
    "df_compras = pd.read_excel(excel_path_5_compras)\n",
    "df_mostrador = pd.read_excel(excel_path_6_mostrador)\n",
    "df_invertidas = pd.read_excel(excel_path_7_invertidas)\n",
    "df_taller_orden_venta = pd.read_excel(excel_path_8_taller_orden_venta)\n",
    "df_cliente = pd.read_excel(excel_path_9_cliente)\n",
    "df_articulos = pd.read_excel(excel_path_10_articulo)\n",
    "df_empresas = pd.read_excel(excel_path_11_empresas)\n",
    "df_talleres = pd.read_excel(excel_path_12_talleres)\n",
    "df_almacenes = pd.read_excel(excel_path_13_almacenes)\n",
    "df_operarios = pd.read_excel(excel_path_14_operarios)\n",
    "df_vehiculos = pd.read_excel(excel_path_15_vehiculo)\n",
    "df_tipos_horas = pd.read_excel(excel_path_16_tipos_horas)\n",
    "df_tipos_venta = pd.read_excel(excel_path_17_tipos_venta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conexión con capa bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# = Connection to schema ddbb =\n",
    "\n",
    "# Define database type and port \n",
    "db_type = 'postgresql' \n",
    "port = 5432\n",
    "\n",
    "# Get schema name acording to layer name\n",
    "db_schema = 'bronze'\n",
    "\n",
    "# Create engine for the specific schema\n",
    "engine = engine_setting(db_type=db_type, db_port=port, db_schema=db_schema)\n",
    "\n",
    "# Establish the connection\n",
    "conn = engine_connection(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones de limpieza y transformación de datos.\n",
    "\n",
    "- Eliminar columnas completamente vacias.\n",
    "- Eliminar espacios vacios en cada registro.\n",
    "- Verificar las columns que podrían ser números enteros 11 en lugar de 11.0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df (df):\n",
    "    '''\n",
    "    '''\n",
    "    df.dropna(how='all', inplace=True)\n",
    "\n",
    "    for columun in df.columns:\n",
    "        df = df[~df[columun].str.contains('\\*\\*\\*', na=False)]\n",
    "    \n",
    "    for col in df.columns:\n",
    "        \n",
    "        if np.issubdtype(df[col].dtype, np.floating):\n",
    "           \n",
    "            df[col] = df[col].fillna(0)\n",
    "            df[col] = df[col].astype('int')\n",
    "            df[col] = df[col].replace(0, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_to_str (df):\n",
    "    '''\n",
    "    Cleans each column in the dataframe by removing leading and trailing whitespace \n",
    "    and ensures that all values are of string type.\n",
    "    \n",
    "    input:\n",
    "        df (pd.DataFrame): DataFrame with columns to be cleaned and converted.\n",
    "    \n",
    "    return:\n",
    "        df (pd.DataFrame): DataFrame with cleaned columns and values converted to string type.\n",
    "    '''\n",
    "    for column in df.columns:\n",
    "        df[column] = df[column].str.lstrip()\n",
    "        df[column] = df[column].str.rstrip()\n",
    "        df[column] = df[column].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data upload - Master tables\n",
    "\n",
    "### Update new data\n",
    "\n",
    "**Step 1**: Get existing values of the reference column in ddbb table.\n",
    "\n",
    "**Step 2**: Compare dataframe values with ddbb existing values.\n",
    "\n",
    "**Step 3**: If there are new values, values are going to be written in th bbdd.\n",
    "\n",
    "**Considerations**\n",
    "- All handle values need to be str type.\n",
    "- Clean white spaces for all values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_existing_values (table_name, column_name):\n",
    "    '''\n",
    "    Get existing values of key column from table in ddbb.\n",
    "\n",
    "    input:\n",
    "        table_name (str): table name in database.\n",
    "        column_name (sts): column name of table in database.\n",
    "\n",
    "    output:\n",
    "        existing_values (list): list of exisitng values in database.  \n",
    "    '''\n",
    "    query = f'SELECT \"{column_name}\" FROM \"{table_name}\"'\n",
    "    existing_values = pd.read_sql(query, con=engine)[column_name].tolist()\n",
    "    \n",
    "    return(existing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_values (df_name, key_column_name, existing_values):\n",
    "    '''\n",
    "    Get the dataframe rows which not exist in table database.\n",
    "\n",
    "    input: \n",
    "        df_name (str): dataframe that is compared with existing values in ddbb.\n",
    "        key_column_name (str): key column name of the dataframe to be compared.\n",
    "        existing_values (list): list of existing values in ddbb. \n",
    "    '''\n",
    "    df_new_values = df_name[~df_name[key_column_name].isin(existing_values)]\n",
    "    \n",
    "    return df_new_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_new_values (df_new_values, db_table_name):\n",
    "    '''\n",
    "    Write new found values in ddbb table. \n",
    "    '''\n",
    "    df_new_values.to_sql(db_table_name, con=engine, if_exists='append', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One function \n",
    "\n",
    "def upload_new_data (table_name, df, key_column, engine):\n",
    "    '''\n",
    "    Process new values: \n",
    "    - Get existing values from the database.\n",
    "    - Identify new values in the dataframe.\n",
    "    - Write new values to the database table.\n",
    "\n",
    "    input: \n",
    "        table_name (str): name of the table in the database.\n",
    "        df (DataFrame): dataframe to be compared with existing values.\n",
    "        key_column (str): key column name in the dataframe and table database to compare.\n",
    "        engine (SQLAlchemy engine): database connection.\n",
    "\n",
    "    output:\n",
    "        None\n",
    "    '''\n",
    "    # Get existing values from the database\n",
    "    query = f'SELECT \"{key_column}\" FROM \"{table_name}\"'\n",
    "    existing_values = pd.read_sql(query, con=engine)[key_column].tolist()\n",
    "\n",
    "    # Get new data by comparing dataframe with existing values\n",
    "    df_new_data = df[~df[key_column].isin(existing_values)]\n",
    "\n",
    "    # Write new values to the database\n",
    "    if not df_new_data.empty:\n",
    "        df_new_data.to_sql(table_name, con=engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Modified Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data form database\n",
    "\n",
    "def get_database_table (table_name):\n",
    "\n",
    "    query = f'SELECT * FROM \"{table_name}\"'\n",
    "    db_table = pd.read_sql(query, con=engine)\n",
    "\n",
    "    return (db_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modified_data (df, db_table, key_column):\n",
    "    '''\n",
    "    Verify and get modified data comparing to existing data in database.\n",
    "\n",
    "    input:\n",
    "        - df (DataFrame): DataFrame to compare.\n",
    "        - db_table (DataFrame): Dataframe with existing data from database.\n",
    "        - key_colum (str): name of key column with is going to be used to merge both DataFrames.\n",
    "    \n",
    "    output:\n",
    "        - modified_data (DataFrame): DataFrame with modified data. \n",
    "    '''\n",
    "    merge_data = df.merge(\n",
    "        db_table, on=key_column,\n",
    "        suffixes=('_new', '_db')\n",
    "    )\n",
    "\n",
    "    # Make sure both DataFrames have the same column names and index\n",
    "    new_merge_data = merge_data.filter(regex='_new$').sort_index(axis=1)\n",
    "    db_data = merge_data.filter(regex='_db$').sort_index(axis=1)\n",
    "\n",
    "    # Otherwise column names are adjusted\n",
    "    new_merge_data.columns = new_merge_data.columns.str.replace('_new$', '', regex=True)\n",
    "    db_data.columns = db_data.columns.str.replace('_db$', '', regex=True)\n",
    "\n",
    "    # Compare rows where there are differences\n",
    "    modified_data = merge_data[(new_merge_data != db_data).any(axis=1)]\n",
    "\n",
    "    return modified_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_modified_data (modified_data, key_column, db_table_name):\n",
    "    '''\n",
    "    description\n",
    "    '''\n",
    "    for _, fila in modified_data.iterrows():\n",
    "        # Create dictionary of columns with nuew values\n",
    "        valores = {col.replace('_new', ''): fila[col] for col in modified_data.filter(regex='_new$').columns}\n",
    "        key_value = fila[key_column]\n",
    "\n",
    "        # Excecute update query\n",
    "        set_clause = ', '.join([f'\"{col}\" = :{col}' for col in valores.keys()])\n",
    "        query = f'UPDATE \"{db_table_name}\" SET {set_clause} WHERE \"{key_column}\" = :key_value'\n",
    "        valores['key_value'] = key_value\n",
    "        engine.execute(query, valores)\n",
    "        print(f\"{len(modified_data)} registros actualizados en '{db_table_name}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabla Empresas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulación actualización de nuevos datos\n",
    "\n",
    "# Datos a verificar\n",
    "df_empresas\n",
    "\n",
    "# Convertir cada columna individualmente a texto\n",
    "for col in df_empresas.columns:\n",
    "    df_empresas[col] = df_empresas[col].astype(str)\n",
    "\n",
    "df_empresas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos existentes en base de datos\n",
    "db_empresas = df_empresas.head(1).copy() \n",
    "\n",
    "# Convertir cada columna individualmente a texto\n",
    "for col in db_empresas.columns:\n",
    "    db_empresas[col] = db_empresas[col].astype(str)\n",
    "\n",
    "db_empresas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_empresas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checking_values = df_empresas['Codig']\n",
    "print(checking_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparación de valores \n",
    "existing_values = db_empresas['Codig'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(existing_values)\n",
    "print(df_empresas['Codig'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empresas_new = df_empresas[~df_empresas['Codig'].isin(existing_values)]\n",
    "df_empresas_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload new data execution\n",
    "upload_new_data ('Empresas U6311303', df_empresas, 'Codig', engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update modified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulación \n",
    "\n",
    "df_empresas_mod = df_empresas.copy()\n",
    "df_empresas_mod.loc[df_empresas_mod['Codig'] == '13', 'Nombre'] = 'Nombre Empresa Modificado'\n",
    "df_empresas_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empresas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_data = df_empresas_mod.merge(\n",
    "        df_empresas, on='Codig',\n",
    "        suffixes=('_new', '_db')\n",
    "    )\n",
    "merge_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and make sure both DataFrames have the same column names and index\n",
    "new_merge_data = merge_data.filter(regex='_new$').sort_index(axis=1)\n",
    "db_data = merge_data.filter(regex='_db$').sort_index(axis=1)\n",
    "\n",
    "# Otherwise column names are adjusted\n",
    "new_merge_data.columns = new_merge_data.columns.str.replace('_new$', '', regex=True)\n",
    "db_data.columns = db_data.columns.str.replace('_db$', '', regex=True)\n",
    "\n",
    "# Compare rows where there are differences\n",
    "modified_data = merge_data[(new_merge_data != db_data).any(axis=1)]\n",
    "\n",
    "modified_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabla Almacenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_almacenes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabla Operarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_operarios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_operarios.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_operarios.dropna(how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_operarios.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_operarios = df_operarios[~df_operarios['Codigo'].str.contains('\\*\\*\\*', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_operarios.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabla vehículos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vehiculos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_vehiculos.columns:\n",
    "    if np.issubdtype(df_vehiculos[col].dtype, np.floating):  # Verificamos si la columna es de tipo float\n",
    "        # Reemplazar NaN por 0\n",
    "        df_vehiculos[col] = df_vehiculos[col].fillna(0)\n",
    "        \n",
    "        # Convertir la columna a tipo entero\n",
    "        df_vehiculos[col] = df_vehiculos[col].astype('int')\n",
    "        \n",
    "        # Reemplazar 0 por NaN\n",
    "        df_vehiculos[col] = df_vehiculos[col].replace(0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vehiculos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vehiculos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabla Tipos Horas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tipos_horas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tipos_horas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabla Tipos Ventas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tipos_venta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tipos_venta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabla Cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cliente.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cliente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabla Articulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articulos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_talleres.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabla Talleres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_talleres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data update - Fact tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bonos_trab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taller_orden_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bono_pres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mostrador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_invertidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taller_orden_venta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maestros\n",
    "# df_empresas.to_sql('Empresas U6311303', con=engine, if_exists='append', index=False) # ok \n",
    "# df_almacenes.to_sql('Almacenes U6321303', con=engine, if_exists='append', index=False) # ok \n",
    "# df_operarios.to_sql('Operarios U6331303', con=engine, if_exists='append', index=False) # ok\n",
    "# df_vehiculos.to_sql('Vehiculo U6341303', con=engine, if_exists='append', index=False) # ok\n",
    "# df_tipos_horas.to_sql('TipoHoras ULSTTHPT', con=engine, if_exists='append', index=False) # ok\n",
    "# df_tipos_venta.to_sql('TipoVentasAlmacen ULSTTVPT', con=engine, if_exists='append', index=False) # ok\n",
    "# df_cliente.to_sql('Cliente U6301303', con=engine, if_exists='append', index=False) # ok \n",
    "# df_articulos.to_sql('Articulo U6301303', con=engine, if_exists='append', index=False) # ok\n",
    "# df_talleres.to_sql('Talleres U6311303', con=engine, if_exists='append', index=False) # ok \n",
    "\n",
    "# # hechos\n",
    "# df_bonos_trab.to_sql('BonosTrabajadas U532', con=engine, if_exists='append', index=False) # ok \n",
    "# df_taller_orden_rep.to_sql('Taller OrdenReparacion U533', con=engine, if_exists='append', index=False) # ok\n",
    "# df_bono_pres.to_sql('BonosPresencia U551', con=engine, if_exists='append', index=False) # ok\n",
    "# df_stock.to_sql('Stock U552', con=engine, if_exists='append', index=False) # ok\n",
    "# df_compras.to_sql('Compras U553', con=engine, if_exists='append', index=False) # ok\n",
    "# df_mostrador.to_sql('Taller OrdenVentaMostrador U554', con=engine, if_exists='append', index=False) # ok\n",
    "# df_invertidas.to_sql('Invertidas U555', con=engine, if_exists='append', index=False) # ok\n",
    "# df_taller_orden_venta.to_sql('Taller OrdenVentaTaller U560', con=engine, if_exists='append', index=False) # ok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if conn:\n",
    "    conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
