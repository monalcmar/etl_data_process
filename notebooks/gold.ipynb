{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalize upload functions given relation diccionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import date, timedelta\n",
    "from sqlalchemy import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar modulos propios en notebook\n",
    "project_root = Path(os.getcwd()).parent\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-23 13:30:10,096 - INFO - Successful connection to schema bronze\n",
      "2024-12-23 13:30:10,126 - INFO - Successful connection to schema silver\n",
      "2024-12-23 13:30:10,160 - INFO - Successful connection to schema gold\n"
     ]
    }
   ],
   "source": [
    "import dependencies as dp\n",
    "from db.engines import engine_silver, conn_silver, engine_gold, conn_gold\n",
    "from processes.extract.functions import map_db_tables, db_tables_to_df\n",
    "from processes.transform.functions import check_nulls, check_data_types\n",
    "from processes.load.functions import get_new_data, upload_new_data, get_modified_data, update_modified_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.gold_schema_mappings import (\n",
    "    pkey_mapping,\n",
    "    fkey_mapping,\n",
    "    column_name_mapping,\n",
    "    # fk_column_silver_mapping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.table_relations import related_silv_gold_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = conn_gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-23 13:30:10,270 - INFO - Mapping database tables in schema 'silver' started.\n",
      "2024-12-23 13:30:10,363 - INFO - Tables in schema 'silver' were successfully mapped.\n",
      "2024-12-23 13:30:10,363 - INFO - Loading data from silver.Almacenes table...\n",
      "2024-12-23 13:30:10,363 - DEBUG - Data from Almacenes table has been load in a DataFrame.\n",
      "2024-12-23 13:30:10,363 - INFO - Loading data from silver.Articulos table...\n",
      "2024-12-23 13:30:11,059 - DEBUG - Data from Articulos table has been load in a DataFrame.\n",
      "2024-12-23 13:30:11,063 - INFO - Loading data from silver.BonosPresencia table...\n",
      "2024-12-23 13:30:12,690 - DEBUG - Data from BonosPresencia table has been load in a DataFrame.\n",
      "2024-12-23 13:30:12,690 - INFO - Loading data from silver.BonosTrabajadas table...\n",
      "2024-12-23 13:30:16,160 - DEBUG - Data from BonosTrabajadas table has been load in a DataFrame.\n",
      "2024-12-23 13:30:16,160 - INFO - Loading data from silver.Clientes table...\n",
      "2024-12-23 13:30:16,503 - DEBUG - Data from Clientes table has been load in a DataFrame.\n",
      "2024-12-23 13:30:16,503 - INFO - Loading data from silver.Compras table...\n",
      "2024-12-23 13:30:19,815 - DEBUG - Data from Compras table has been load in a DataFrame.\n",
      "2024-12-23 13:30:19,829 - INFO - Loading data from silver.Empresas table...\n",
      "2024-12-23 13:30:19,830 - DEBUG - Data from Empresas table has been load in a DataFrame.\n",
      "2024-12-23 13:30:19,830 - INFO - Loading data from silver.Invertidas table...\n",
      "2024-12-23 13:30:22,224 - DEBUG - Data from Invertidas table has been load in a DataFrame.\n",
      "2024-12-23 13:30:22,224 - INFO - Loading data from silver.Operarios table...\n",
      "2024-12-23 13:30:22,224 - DEBUG - Data from Operarios table has been load in a DataFrame.\n",
      "2024-12-23 13:30:22,224 - INFO - Loading data from silver.Stock table...\n",
      "2024-12-23 13:30:22,326 - DEBUG - Data from Stock table has been load in a DataFrame.\n",
      "2024-12-23 13:30:22,326 - INFO - Loading data from silver.OrdenesReparacion table...\n",
      "2024-12-23 13:30:24,808 - DEBUG - Data from OrdenesReparacion table has been load in a DataFrame.\n",
      "2024-12-23 13:30:24,808 - INFO - Loading data from silver.OrdenesVentaMostrador table...\n",
      "2024-12-23 13:30:26,034 - DEBUG - Data from OrdenesVentaMostrador table has been load in a DataFrame.\n",
      "2024-12-23 13:30:26,034 - INFO - Loading data from silver.OrdenesVentaTaller table...\n",
      "2024-12-23 13:30:39,036 - DEBUG - Data from OrdenesVentaTaller table has been load in a DataFrame.\n",
      "2024-12-23 13:30:39,036 - INFO - Loading data from silver.Talleres table...\n",
      "2024-12-23 13:30:39,048 - DEBUG - Data from Talleres table has been load in a DataFrame.\n",
      "2024-12-23 13:30:39,048 - INFO - Loading data from silver.TiposHoras table...\n",
      "2024-12-23 13:30:39,053 - DEBUG - Data from TiposHoras table has been load in a DataFrame.\n",
      "2024-12-23 13:30:39,053 - INFO - Loading data from silver.TiposOrdenesReparacion table...\n",
      "2024-12-23 13:30:39,053 - DEBUG - Data from TiposOrdenesReparacion table has been load in a DataFrame.\n",
      "2024-12-23 13:30:39,053 - INFO - Loading data from silver.TiposVentasAlmacen table...\n",
      "2024-12-23 13:30:39,059 - DEBUG - Data from TiposVentasAlmacen table has been load in a DataFrame.\n",
      "2024-12-23 13:30:39,059 - INFO - Loading data from silver.Vehiculos table...\n",
      "2024-12-23 13:30:39,580 - DEBUG - Data from Vehiculos table has been load in a DataFrame.\n",
      "2024-12-23 13:30:39,580 - INFO - Data from all tables has been successfully loaded into DataFrames.\n",
      "2024-12-23 13:30:39,580 - INFO - Extract Historic Data Process executed successfully in silver schema.\n"
     ]
    }
   ],
   "source": [
    "# extract data from silver \n",
    "try:\n",
    "    db_tables = map_db_tables(engine=engine_silver, schema='silver')\n",
    "    silver_df = db_tables_to_df(engine=engine_silver, tables=db_tables)\n",
    "    dp.logger.info(f\"Extract Historic Data Process executed successfully in silver schema.\")\n",
    "\n",
    "except Exception as e:\n",
    "    dp.logger.error(f\"Extract Historic Data Proccess failed in bronze schema.: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_tables = [\n",
    "    # \"TiposOrdenesReparacion\",\n",
    "    # \"TiposVentasAlmacen\",\n",
    "    # \"Articulos\",\n",
    "    # \"TiposHoras\",\n",
    "    # \"Clientes\",\n",
    "    # \"Empresas\",\n",
    "    # \"Vehiculos\",\n",
    "    # \"Talleres\",\n",
    "    # \"Operarios\",\n",
    "    # \"Almacenes\",\n",
    "    # #\"Stock\",\n",
    "    # \"BonosPresencia\",\n",
    "    # \"OrdenesReparacion\",\n",
    "    # \"BonosTrabajadas\",\n",
    "    \"Compras\",\n",
    "    # \"Invertidas\",\n",
    "    # # \"OrdenesVentaMostrador\",\n",
    "    # # \"OrdenesVentaTaller\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.functions import build_upload_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.model_info import gold_properties\n",
    "from model.gold_schema_mappings import fkey_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.functions import build_upload_query\n",
    "from model.model_info import gold_properties\n",
    "from model.gold_schema_mappings import fkey_mapping\n",
    "\n",
    "def assing_foreig_keys (tbl_gold, df_silver, fk_relations, conn):\n",
    "    '''\n",
    "    This function assign Foreign Keys to the tables which has to be assinged. \n",
    "\n",
    "    input:\n",
    "        - tbl_gold (str): Name of the table which Fkeys are assigned.\n",
    "        - df_silver (DataFrame): df which Fkeys are goint to be assigned.\n",
    "        - fk_relations (Dictionary): Dictionary with the Foreign Keys information. \n",
    "\n",
    "    output:\n",
    "        - df_fkeys_assigned (DataFrame): The python DataFrame with all its Foreign Keys assigned.\n",
    "    '''\n",
    "    # define empty df to store df with fkeys assigned\n",
    "    df_merge_fkeys = df_silver\n",
    "\n",
    "    for fkey_name, fkey_details in fk_relations.items():\n",
    "        dp.logger.info(f\"Assigning column '{fkey_name}' to table '{tbl_gold}' stracted from Silver Schema.\")\n",
    "\n",
    "        # define empty df to store df with fkeys assigned\n",
    "        # df_merge_fkeys = df_silver\n",
    "\n",
    "        # Assign keys from the dictionary of each Fkey dictionary\n",
    "        tbl = fkey_details['tbl']\n",
    "        select_columns = fkey_details['select_columns']\n",
    "        left_on = fkey_details['left_on']\n",
    "        right_on = fkey_details['right_on']\n",
    "        pk_to_fk = fkey_details['pk_to_fk']\n",
    "\n",
    "        # Construct query for the foreign table\n",
    "        query = build_upload_query(\n",
    "            table_name=tbl,\n",
    "            key_columns=select_columns,\n",
    "            date_column=None\n",
    "        )\n",
    "\n",
    "        foreing_tbl = pd.read_sql(query, con=conn)\n",
    "\n",
    "        # IMPORTANTE: Comprobar que los tipos de datos en left_on y right_on son idénticos este codigo se rompio por los rights_on cambiados a listas.\n",
    "\n",
    "        ## APAÑO DE LO IMPORTANTE ARRIBA\n",
    "\n",
    "        # Define suffixes when principal and foreign table are merge    \n",
    "        merge_suffixes = (\"_silver\", \"_foreign\")\n",
    "\n",
    "        ####### APAÑO #######\n",
    "        if tbl_gold in {'BonosTrabajadas', 'Invertidas'} and fkey_name == 'FkOrdenReparacion':\n",
    "            df_merge_fkeys[left_on] = df_merge_fkeys[left_on].astype('Int64').astype(str)\n",
    "            df_merge_fkeys[left_on] = df_merge_fkeys[left_on].replace('<NA>', None)\n",
    "\n",
    "        # Realizar el merge acumulativo\n",
    "        df_merge_fkeys = pd.merge(\n",
    "            df_merge_fkeys,\n",
    "            foreing_tbl,\n",
    "            left_on=left_on,\n",
    "            right_on=right_on,\n",
    "            how='left',\n",
    "            suffixes=merge_suffixes\n",
    "        )\n",
    "\n",
    "        # Renaming columns acording to 'pk_to_fk'\n",
    "        df_merge_fkeys = df_merge_fkeys.rename(columns=pk_to_fk)\n",
    "\n",
    "        # Identify duplicate foreign columns after merge\n",
    "        duplicated_columns = [col for col in df_merge_fkeys.columns if col.endswith(\"_foreign\")]\n",
    "        for col in duplicated_columns:\n",
    "            dp.logger.info(f\"Removing unnecessary foreign column '{col}' from the table '{tbl_gold}'.\")\n",
    "            df_merge_fkeys = df_merge_fkeys.drop(columns=[col])\n",
    "\n",
    "        # Restore original silver column names (if applicable)\n",
    "        renamed_columns = {col: col.replace(\"_silver\", \"\") for col in df_merge_fkeys.columns if col.endswith(\"_silver\")}\n",
    "        \n",
    "        if renamed_columns:\n",
    "            dp.logger.info(f\"Renaming columns to their original names: {renamed_columns}\")\n",
    "            df_merge_fkeys = df_merge_fkeys.rename(columns=renamed_columns)\n",
    "\n",
    "    ##### APAÑO #### ¡Creo que ya no es necesario, pero verificar, porque esta corregido en el modelo! ¡CORREGIDO!\n",
    "    # if tbl_gold == 'Vehiculos':\n",
    "    #     df_merge_fkeys = df_merge_fkeys.rename(columns={'FechaUltimo':'FechaUltimaVisita'})    \n",
    "\n",
    "    df_merge_fkeys = df_merge_fkeys[gold_properties[tbl_gold].keys()]\n",
    "\n",
    "    dp.logger.debug(f\"Foreign key assignment for table '{tbl_gold}' completed.\")\n",
    "\n",
    "    return df_merge_fkeys\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_silver_fkeys = {}\n",
    "\n",
    "for tbl_gold in ordered_tables:\n",
    "    dp.logger.info(f\"Processing table: Silver '{tbl_gold}' -> Gold '{tbl_gold}'\")\n",
    "\n",
    "    #df_silver_fkeys = {}\n",
    "\n",
    "    if tbl_gold in fkey_mapping.keys():\n",
    "        dp.logger.debug(f'Table {tbl_gold} needs to assign foreign keys.')\n",
    "        \n",
    "        # Obtener relaciones de claves foráneas de la tabla\n",
    "        fk_relations = fkey_mapping[tbl_gold]\n",
    "        dp.logger.debug(f\"FK Processing table: {tbl_gold}\")\n",
    "\n",
    "        df_silver_fkeys[tbl_gold] = assing_foreig_keys (\n",
    "            tbl_gold,\n",
    "            silver_df[tbl_gold],\n",
    "            fkey_mapping[tbl_gold],\n",
    "            conn\n",
    "        )\n",
    "    else:\n",
    "        df_silver_fkeys[tbl_gold] = silver_df[tbl_gold]\n",
    "\n",
    "    dp.logger.debug(f\"Applying transforme functions to '{tbl_gold}'\")\n",
    "\n",
    "    df_silver_fkeys[tbl_gold], df_null_rows = check_nulls(df_silver_fkeys[tbl_gold], gold_properties[tbl_gold])\n",
    "\n",
    "    df_silver_fkeys[tbl_gold], df_invalid = check_data_types(df_silver_fkeys[tbl_gold], gold_properties[tbl_gold], df_null_rows)\n",
    "\n",
    "    table_relations = related_silv_gold_v2[tbl_gold]\n",
    "    for relation in table_relations:\n",
    "        tbl_silv = relation.get(\"tbl_gold\") ## OJO relation.get(\"tbl_silv\")\n",
    "        df = df_silver_fkeys[tbl_gold] ### OJO  ## silver_df[tbl_gold] \n",
    "        table_name = tbl_gold\n",
    "        key_columns = relation.get(\"key_columns\")\n",
    "        date_column = relation.get(\"date_column\")\n",
    "\n",
    "\n",
    "    df_new_data, df_existing_data = get_new_data (\n",
    "        df=df, \n",
    "        table_name=table_name,\n",
    "        key_columns=key_columns,\n",
    "        date_column=date_column,\n",
    "        engine=engine_gold)\n",
    "    \n",
    "    if not df_new_data.empty:\n",
    "        dp.logger.info(f'There is new data to upload in table \"{table_name}\"')\n",
    "\n",
    "        dp.logger.info(f\"Assigning new IDs for table '{tbl_gold}'\")\n",
    "        pkey_column = pkey_mapping.get(tbl_gold)\n",
    "\n",
    "        result = conn.execute(\n",
    "            text(f'SELECT MAX(\"{pkey_column}\") FROM \"gold\".\"{tbl_gold}\"')\n",
    "        )\n",
    "\n",
    "        max_existing_id = result.scalar() or 0\n",
    "\n",
    "        df_new_data[pkey_column] = range( # silver_df\n",
    "            max_existing_id + 1, max_existing_id + 1 + len(df_new_data)\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            upload_new_data(\n",
    "                df_new_data=df_new_data,\n",
    "                table_name=table_name, \n",
    "                date_column=date_column, \n",
    "                engine=engine_gold)\n",
    "            \n",
    "            dp.logger.info(f'New data has been uploaded succesfully into table \"{tbl_gold}\"')\n",
    "\n",
    "        except Exception as e:\n",
    "            dp.logger.error(f\"An error has occurred trying to insert new data into table '{tbl_gold}': {e}\")\n",
    "            continue\n",
    "            \n",
    "    else:\n",
    "        dp.logger.info(f'There is not update data to insert into table \"{table_name}\"')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_silver_fkeys = {}\n",
    "\n",
    "for tbl_gold in ordered_tables:\n",
    "    dp.logger.info(f\"Processing table: Silver '{tbl_gold}' -> Gold '{tbl_gold}'\")\n",
    "\n",
    "    #df_silver_fkeys = {}\n",
    "\n",
    "    if tbl_gold in fkey_mapping.keys():\n",
    "        dp.logger.debug(f'Table {tbl_gold} needs to assign foreign keys.')\n",
    "        \n",
    "        # Obtener relaciones de claves foráneas de la tabla\n",
    "        fk_relations = fkey_mapping[tbl_gold]\n",
    "        dp.logger.debug(f\"FK Processing table: {tbl_gold}\")\n",
    "\n",
    "        df_silver_fkeys[tbl_gold] = assing_foreig_keys (\n",
    "            tbl_gold,\n",
    "            silver_df[tbl_gold],\n",
    "            fkey_mapping[tbl_gold],\n",
    "            conn\n",
    "        )\n",
    "    else:\n",
    "        df_silver_fkeys[tbl_gold] = silver_df[tbl_gold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fk_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assing_foreig_keys (\n",
    "            tbl_gold,\n",
    "            silver_df[tbl_gold],\n",
    "            fkey_mapping[tbl_gold],\n",
    "            conn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_df[tbl_gold]['FkAlmacen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tbl_gold in ordered_tables:\n",
    "\n",
    "    if tbl_gold in fkey_mapping.keys():\n",
    "        dp.logger.debug(f'Table {tbl_gold} needs to assign foreign keys.')\n",
    "        \n",
    "        # Obtener relaciones de claves foráneas de la tabla\n",
    "        fk_relations = fkey_mapping[tbl_gold]\n",
    "        dp.logger.debug(f\"FK Processing table: {tbl_gold}\")\n",
    "                \n",
    "        for fkey_name, fkey_details in fk_relations.items():\n",
    "            dp.logger.info(f\"Assigning column '{fkey_name}' from Silver for FK processing in table '{tbl_gold}'.\")\n",
    "            \n",
    "            # Detalles de la relación\n",
    "            tbl = fkey_details['tbl']\n",
    "            select_columns = fkey_details['select_columns']\n",
    "            left_on = fkey_details['left_on']\n",
    "            right_on = fkey_details['right_on']\n",
    "            pk_to_fk = fkey_details['pk_to_fk']\n",
    "            \n",
    "            # Construir consulta para la tabla foránea\n",
    "            query = build_upload_query(\n",
    "                table_name=tbl,\n",
    "                key_columns=select_columns,\n",
    "                date_column=None\n",
    "            )\n",
    "            foreing_tbl = pd.read_sql(query, con=engine_gold)\n",
    "\n",
    "            merge_suffixes = (\"_silver\", \"_foreign\")\n",
    "\n",
    "\n",
    "            ####### APAÑO #######\n",
    "            if tbl_gold == 'BonosTrabajadas' and fkey_name == 'FkOrdenReparacion':\n",
    "                silver_df[tbl_gold][left_on] = silver_df[tbl_gold][left_on].astype('Int64').astype(str)\n",
    "                silver_df[tbl_gold][left_on] = silver_df[tbl_gold][left_on].replace('<NA>', None)\n",
    "\n",
    "            # Realizar el merge acumulativo\n",
    "            silver_df[tbl_gold] = pd.merge(\n",
    "                silver_df[tbl_gold],\n",
    "                foreing_tbl,\n",
    "                left_on=left_on,\n",
    "                right_on=right_on,\n",
    "                how='left',\n",
    "                suffixes=merge_suffixes\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fkey_name, fkey_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_df[tbl_gold].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tbl_gold in ordered_tables:\n",
    "\n",
    "    if tbl_gold in fkey_mapping.keys():\n",
    "        dp.logger.debug(f'Table {tbl_gold} needs to assign foreign keys.')\n",
    "        \n",
    "        # Obtener relaciones de claves foráneas de la tabla\n",
    "        fk_relations = fkey_mapping[tbl_gold]\n",
    "        dp.logger.debug(f\"FK Processing table: {tbl_gold}\")\n",
    "                \n",
    "        for fkey_name, fkey_details in fk_relations.items():\n",
    "            dp.logger.info(f\"Assigning column '{fkey_name}' from Silver for FK processing in table '{tbl_gold}'.\")\n",
    "            \n",
    "            # Detalles de la relación\n",
    "            tbl = fkey_details['tbl']\n",
    "            select_columns = fkey_details['select_columns']\n",
    "            left_on = fkey_details['left_on']\n",
    "            right_on = fkey_details['right_on']\n",
    "            pk_to_fk = fkey_details['pk_to_fk']\n",
    "            \n",
    "            # Construir consulta para la tabla foránea\n",
    "            query = build_upload_query(\n",
    "                table_name=tbl,\n",
    "                key_columns=select_columns,\n",
    "                date_column=None\n",
    "            )\n",
    "            foreing_tbl = pd.read_sql(query, con=engine_gold)\n",
    "            \n",
    "            # IMPORTANTE: Comprobar que los tipos de datos en left_on y right_on son idénticos este codigo se rompio por los rights_on cambiados a listas.\n",
    "\n",
    "            ## APAÑO DE LO IMPORTANTE ARRIBA\n",
    "            \n",
    "            merge_suffixes = (\"_silver\", \"_foreign\")\n",
    "\n",
    "\n",
    "            ####### APAÑO #######\n",
    "            if tbl_gold == 'BonosTrabajadas' and fkey_name == 'FkOrdenReparacion':\n",
    "                silver_df[tbl_gold][left_on] = silver_df[tbl_gold][left_on].astype('Int64').astype(str)\n",
    "                silver_df[tbl_gold][left_on] = silver_df[tbl_gold][left_on].replace('<NA>', None)\n",
    "\n",
    "            # Realizar el merge acumulativo\n",
    "            silver_df[tbl_gold] = pd.merge(\n",
    "                silver_df[tbl_gold],\n",
    "                foreing_tbl,\n",
    "                left_on=left_on,\n",
    "                right_on=right_on,\n",
    "                how='left',\n",
    "                suffixes=merge_suffixes\n",
    "            )\n",
    "            \n",
    "            # Renombrar columnas según `pk_to_fk`\n",
    "            silver_df[tbl_gold] = silver_df[tbl_gold].rename(columns=pk_to_fk)\n",
    "\n",
    "            # Manejar la eliminación de columnas duplicadas\n",
    "            right_on_foreign = f\"{right_on}_foreign\"  # Nombre esperado después del merge\n",
    "            left_on_silver = f\"{left_on}_silver\"      # Nombre esperado después del merge\n",
    "\n",
    "            # Identificar columnas foráneas duplicadas después del merge\n",
    "            duplicated_columns = [col for col in silver_df[tbl_gold].columns if col.endswith(\"_foreign\")]\n",
    "            for col in duplicated_columns:\n",
    "                dp.logger.info(f\"Removing unnecessary foreign column '{col}' from the table '{tbl_gold}'.\")\n",
    "                silver_df[tbl_gold] = silver_df[tbl_gold].drop(columns=[col])\n",
    "\n",
    "            # Restaurar nombres originales de las columnas de silver (si aplica)\n",
    "            renamed_columns = {col: col.replace(\"_silver\", \"\") for col in silver_df[tbl_gold].columns if col.endswith(\"_silver\")}\n",
    "            if renamed_columns:\n",
    "                dp.logger.info(f\"Renaming columns to their original names: {renamed_columns}\")\n",
    "                silver_df[tbl_gold] = silver_df[tbl_gold].rename(columns=renamed_columns)\n",
    "\n",
    "        ##### APAÑO ####\n",
    "        if tbl_gold == 'Vehiculos':\n",
    "            silver_df[tbl_gold] = silver_df[tbl_gold].rename(columns={'FechaUltimo':'FechaUltimaVisita'})    \n",
    "\n",
    "        silver_df[tbl_gold] = silver_df[tbl_gold][gold_properties[tbl_gold].keys()]\n",
    "\n",
    "        dp.logger.debug(f\"Foreign key assignment for table '{tbl_gold}' completed.\")\n",
    "\n",
    "        dp.logger.debug(f\"Applying transforme functions to '{tbl_gold}'\")\n",
    "\n",
    "        # Funciones transform IMPORTANTE: Aplicar a todas las tablas no solo a las de FKs\n",
    "\n",
    "        silver_df[tbl_gold], df_null_rows = check_nulls(silver_df[tbl_gold], gold_properties[tbl_gold])\n",
    "\n",
    "        silver_df[tbl_gold], df_invalid = check_data_types(silver_df[tbl_gold], gold_properties[tbl_gold], df_null_rows)\n",
    "\n",
    "    \n",
    "    table_relations = related_silv_gold_v2[tbl_gold]\n",
    "    for relation in table_relations:\n",
    "        tbl_silv = relation.get(\"tbl_gold\") ## OJO relation.get(\"tbl_silv\")\n",
    "        df = silver_df[tbl_gold] ### OJO  ## silver_df[tbl_gold] \n",
    "        table_name = tbl_gold\n",
    "        key_columns = relation.get(\"key_columns\")\n",
    "        date_column = relation.get(\"date_column\")\n",
    "        \n",
    "\n",
    "\n",
    "    dp.logger.info(f\"Processing table: Silver '{tbl_silv}' -> Gold '{tbl_gold}'\")\n",
    "\n",
    "    df_new_data, df_existing_data = get_new_data (\n",
    "            df=df, \n",
    "            table_name=table_name,\n",
    "            key_columns=key_columns,\n",
    "            date_column=date_column,\n",
    "            engine=engine_gold)\n",
    "            \n",
    "    if not df_new_data.empty:\n",
    "        dp.logger.info(f'There is new data to upload in table \"{table_name}\"')\n",
    "\n",
    "        dp.logger.info(f\"Assigning new IDs for table '{tbl_gold}'\")\n",
    "        pkey_column = pkey_mapping.get(tbl_gold)\n",
    "\n",
    "        result = conn.execute(\n",
    "            text(f'SELECT MAX(\"{pkey_column}\") FROM \"gold\".\"{tbl_gold}\"')\n",
    "        )\n",
    "\n",
    "        max_existing_id = result.scalar() or 0\n",
    "\n",
    "        df_new_data[pkey_column] = range( # silver_df\n",
    "            max_existing_id + 1, max_existing_id + 1 + len(df_new_data)\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            upload_new_data(\n",
    "                df_new_data=df_new_data,\n",
    "                table_name=table_name, \n",
    "                date_column=date_column, \n",
    "                engine=engine_gold)\n",
    "            \n",
    "            dp.logger.info(f'New data has been uploaded succesfully into table \"{tbl_gold}\"')\n",
    "\n",
    "        except Exception as e:\n",
    "            dp.logger.error(f\"An error has occurred trying to insert new data into table '{tbl_gold}': {e}\")\n",
    "            continue\n",
    "            \n",
    "    else:\n",
    "        dp.logger.info(f'There is not update data to insert into table \"{table_name}\"')\n",
    "    \n",
    "\n",
    "    #else:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
